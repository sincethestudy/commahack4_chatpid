{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    del mask\n",
    "    gc.collect()\n",
    "\n",
    "def show_masks_on_image(raw_image, masks):\n",
    "  plt.imshow(np.array(raw_image))\n",
    "  ax = plt.gca()\n",
    "  ax.set_autoscale_on(False)\n",
    "  for mask in masks:\n",
    "      show_mask(mask, ax=ax, random_color=True)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "  del mask\n",
    "  gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline(\"mask-generation\", model=\"facebook/sam-vit-huge\", device=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local image test\n",
    "from PIL import Image\n",
    "\n",
    "raw_image = Image.open(\"crossfar.png\").convert(\"RGB\")\n",
    "\n",
    "plt.imshow(raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = generator(raw_image, points_per_batch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = outputs[\"masks\"]\n",
    "def show_masks_on_image(raw_image, masks, save_path=None):\n",
    "    plt.imshow(np.array(raw_image))\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "    for mask in masks:\n",
    "        show_mask(mask, ax=ax, random_color=True)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "    del mask\n",
    "    gc.collect()\n",
    "show_masks_on_image(raw_image, masks, save_path=\"crossfar_mask.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of masks: {len(outputs['masks'])}\")\n",
    "print(f\"Shape of scores: {outputs['scores'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bmachado/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/bmachado/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask 0: Class envelope\n",
      "Mask 1: Class bulletproof vest\n",
      "Mask 2: Class vulture\n",
      "Mask 3: Class switch\n",
      "Mask 4: Class mortar\n",
      "Mask 5: Class match\n",
      "Mask 6: Class T-shirt\n",
      "Mask 7: Class match\n",
      "Mask 8: Class switch\n",
      "Mask 9: Class T-shirt\n",
      "Mask 10: Class T-shirt\n",
      "Mask 11: Class match\n",
      "Mask 12: Class notebook computer\n",
      "Mask 13: Class match\n",
      "Mask 14: Class bulletproof vest\n",
      "Mask 15: Class notebook computer\n",
      "Mask 16: Class match\n",
      "Mask 17: Class match\n",
      "Mask 18: Class T-shirt\n",
      "Mask 19: Class match\n",
      "Mask 20: Class match\n",
      "Mask 21: Class spotlight\n",
      "Mask 22: Class toilet paper\n",
      "Mask 23: Class match\n",
      "Mask 24: Class match\n",
      "Mask 25: Class quill\n",
      "Mask 26: Class notebook computer\n",
      "Mask 27: Class match\n",
      "Mask 28: Class match\n",
      "Mask 29: Class nematode\n",
      "Mask 30: Class digital clock\n",
      "Mask 31: Class match\n",
      "Mask 32: Class nematode\n",
      "Mask 33: Class analog clock\n",
      "Mask 34: Class match\n",
      "Mask 35: Class match\n",
      "Mask 36: Class cleaver\n",
      "Mask 37: Class match\n",
      "Mask 38: Class match\n",
      "Mask 39: Class match\n",
      "Mask 40: Class match\n",
      "Mask 41: Class envelope\n",
      "Mask 42: Class tennis ball\n",
      "Mask 43: Class plectrum\n",
      "Mask 44: Class match\n",
      "Mask 45: Class match\n",
      "Mask 46: Class match\n",
      "Mask 47: Class match\n",
      "Mask 48: Class match\n",
      "Mask 49: Class match\n",
      "Mask 50: Class syringe\n",
      "Mask 51: Class digital clock\n",
      "Mask 52: Class match\n",
      "Mask 53: Class match\n",
      "Mask 54: Class match\n",
      "Mask 55: Class match\n",
      "Mask 56: Class spotlight\n",
      "Mask 57: Class match\n",
      "Mask 58: Class spotlight\n",
      "Mask 59: Class match\n",
      "Mask 60: Class spotlight\n",
      "Mask 61: Class syringe\n",
      "Mask 62: Class match\n",
      "Mask 63: Class digital clock\n",
      "Mask 64: Class match\n",
      "Mask 65: Class spotlight\n",
      "Mask 66: Class notebook computer\n",
      "Mask 67: Class match\n",
      "Mask 68: Class ping-pong ball\n",
      "Mask 69: Class spotlight\n",
      "Mask 70: Class match\n",
      "Mask 71: Class analog clock\n",
      "Mask 72: Class match\n",
      "Mask 73: Class match\n",
      "Mask 74: Class match\n",
      "Mask 75: Class match\n",
      "Mask 76: Class match\n",
      "Mask 77: Class spotlight\n",
      "Mask 78: Class match\n"
     ]
    }
   ],
   "source": [
    "# %% cell 7\n",
    "\n",
    "import urllib\n",
    "import json\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Load the pretrained model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Download the ImageNet class index\n",
    "class_idx_url = 'https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json'\n",
    "class_idx_str = urllib.request.urlopen(class_idx_url).read()\n",
    "class_idx = json.loads(class_idx_str)\n",
    "\n",
    "# Create a 2D array to represent the image\n",
    "image_text = [[' ']*20 for _ in range(20)]\n",
    "\n",
    "# Calculate the size of each cell in the original image\n",
    "cell_width = raw_image.size[0] // 20\n",
    "cell_height = raw_image.size[1] // 20\n",
    "\n",
    "# Classify each mask\n",
    "for i, mask in enumerate(masks):\n",
    "    # Your existing code to classify the mask...\n",
    "    # Convert mask to PIL image\n",
    "    mask_image = Image.fromarray(mask)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    mask_image = mask_image.convert(\"RGB\")\n",
    "\n",
    "    # Apply transformations\n",
    "    mask_image = transform(mask_image)\n",
    "\n",
    "    # Unsqueeze dimensions\n",
    "    mask_image = mask_image.unsqueeze(0)\n",
    "\n",
    "    # Wrap it in Variable\n",
    "    inputs = Variable(mask_image)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Get the index of the max log-probability\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Get the class name from the class index\n",
    "    class_name = class_idx[predicted.item()]\n",
    "\n",
    "    print(f\"Mask {i}: Class {class_name}\")\n",
    "\n",
    "    # Get the bounding box of the mask\n",
    "    bbox = Image.fromarray(mask).getbbox()\n",
    "\n",
    "    # Calculate the corresponding cells in the text image\n",
    "    cell_x1 = bbox[0] // cell_width\n",
    "    cell_y1 = bbox[1] // cell_height\n",
    "    cell_x2 = (bbox[2] + cell_width - 1) // cell_width\n",
    "    cell_y2 = (bbox[3] + cell_height - 1) // cell_height\n",
    "\n",
    "    # Fill the corresponding cells in the text image with the class name\n",
    "    for y in range(cell_y1, min(cell_y2, 20)):\n",
    "        for x in range(cell_x1, min(cell_x2, 20)):\n",
    "            image_text[y][x] = class_name\n",
    "\n",
    "# Write the text image to a file\n",
    "with open('output.txt', 'w') as f:\n",
    "    for row in image_text:\n",
    "        f.write(' '.join(row))\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
